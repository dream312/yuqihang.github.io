 <!-- FlatFy Theme - Andrea Galanti /-->
 <!doctype html>
 <!--[if lt IE 7]> <html class="no-js ie6 oldie" lang="en"> <![endif]-->
 <!--[if IE 7]>    <html class="no-js ie7 oldie" lang="en"> <![endif]-->
 <!--[if IE 8]>    <html class="no-js ie8 oldie" lang="en"> <![endif]-->
 <!--[if IE 9]>    <html class="no-js ie9" lang="en"> <![endif]-->
 <!--[if gt IE 9]><!--> <html> <!--<![endif]-->
 <head>
     <meta charset="utf-8">
     <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0">
     <meta name="description" content="Flatfy Free Flat and Responsive HTML5 Template ">
     <meta name="author" content="">
 
     <title>Yuqi Hang</title>
 
     <!-- Bootstrap core CSS -->
     <link href="css/bootstrap.min.css" rel="stylesheet">
  
     <!-- Custom Google Web Font -->
     <link href="font-awesome/css/font-awesome.min.css" rel="stylesheet">
     <link href='http://fonts.googleapis.com/css?family=Lato:100,300,400,700,900,100italic,300italic,400italic,700italic,900italic' rel='stylesheet' type='text/css'>
     <link href='http://fonts.googleapis.com/css?family=Arvo:400,700' rel='stylesheet' type='text/css'>
     
     <!-- Custom CSS-->
     <link href="css/general.css" rel="stylesheet">
     
      <!-- Owl-Carousel -->
     <link href="css/custom.css" rel="stylesheet">
     <link href="css/owl.carousel.css" rel="stylesheet">
     <link href="css/owl.theme.css" rel="stylesheet">
     <link href="css/style.css" rel="stylesheet">
     <link href="css/animate.css" rel="stylesheet">
     
     <!-- Magnific Popup core CSS file -->
     <link rel="stylesheet" href="css/magnific-popup.css"> 
     
     <script src="js/modernizr-2.8.3.min.js"></script>  <!-- Modernizr /-->
     <!--[if IE 9]>
         <script src="js/PIE_IE9.js"></script>
     <![endif]-->
     <!--[if lt IE 9]>
         <script src="js/PIE_IE678.js"></script>
     <![endif]-->
 
     <!--[if lt IE 9]>
         <script src="js/html5shiv.js"></script>
     <![endif]-->
 
 </head>
 
 <style>
    .dropdown {
        position: relative;
        display: inline-block;
    }
    .dropdown-content {
        display: none;
        position: absolute;
        background-color: #f9f9f9;
        min-width: 100px;
        box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.2);
        padding: 12px 16px;
        z-index: 1;
    }
    .dropdown:hover .dropdown-content {
        display: block;
    }
</style>

 <body id="home">
 
     <!-- Preloader -->
     <div id="preloader">
         <div id="status"></div>
     </div>
     
     <!-- NavBar-->
     <nav class="navbar-default" role="navigation">
      <div class="container">
          <div class="navbar-header">
              <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                  <span class="sr-only">Toggle navigation</span>
                  <span class="icon-bar"></span>
                  <span class="icon-bar"></span>
                  <span class="icon-bar"></span>
              </button>
              <a class="navbar-brand" href="index.html#home">Yuqi Hang</a>
          </div>

          <div class="collapse navbar-collapse navbar-right navbar-ex1-collapse">
              <ul class="nav navbar-nav">
                  
                 <li class="dropdown"><a href="index.html#concept">Concept</a>
                     <div class="dropdown-content">
                         <p><a href="project_1.html">Project 1</a></p>
                         <p><a href="project_2.html">Project 2</a></p>
                         <p><a href="project_3.html">Project 3</a></p>
                     </div>
                 </li>

                 <li class="dropdown"><a href="index.html#implementation">Implementation</a>
                     <div class="dropdown-content">
                         <p><a href="project_4.html">Project 4</a></p>
                         <p><a href="project_5.html">Project 5</a></p>
                         <p><a href="project_6.html">Project 6</a></p>
                     </div>
                 </li>

                 <li class="dropdown"><a href="index.html#evaluation">Evaluation</a>
                     <div class="dropdown-content">
                         <p><a href="project_7.html">Project 7</a></p>
                     </div>
                 </li>
                 
                 <li class="dropdown"><a href="aboutme.html">About me</a>
                 </li>
                 
              </ul>
          </div>
         
      </div>
  </nav> 

     
     <!-- Project -->
    <div class="container">
      <h3 class="section-heading">Project 2. Comparable semantic representation in neural and computer systems</h3>
    </div>
    
    <div class="container">
      <h4>Publication</h4>

      <div class="col-sm-12">
      <p class="lead">
        Zhang, L., Wang, L., Yang, J., Qian, P., Wang, X., Qiu, X., ... & Tian, X. (2020). Can computers understand words like humans do? Comparable semantic representation in neural and computer systems. bioRxiv.<br> 
        <a class="lead" href="https://doi.org/10.1101/843896"><u>https://doi.org/10.1101/843896v2</u></a> 
      </p>
      </div>
    </div>


    <div class="container">
      <h4>Research Background</h4>

        <div class="col-sm-9 wow fadeInLeftBig">        
          <p class="lead">
            Semantic representation has been studied independently in neuroscience and computer science. 
            <strong>A deep understanding of human neural computations and the revolution to strong artificial intelligence appeal for a joint force in the language domain. </strong>
            We investigated comparable representational formats of lexical semantics between these two complex systems with fine temporal resolution neural recordings. 
            We found semantic representations generated from computational models significantly correlated with EEG responses at an early stage of a typical semantic processing time window in a two-word semantic priming paradigm. 
            Moreover, three representative computational models differentially predicted EEG responses along the dynamics of word processing. 
            Our study provided a finer-grained understanding of the neural dynamics underlying semantic processing and developed an objective biomarker for assessing human-like computation in computational models. 
            Our novel framework trailblazed a promising way to bridge across disciplines in the investigation of higher-order cognitive functions in human and artificial intelligence.

          </p>
        </div>

        <div class="col-sm-3 wow fadeInRightBig">
          <img src="figures/fig2-1.png" alt="fig2-1" width="100%" height="50%">
          <p>Figure 2.1 The Brain Dictionary. Adapted from 
          <a href="https://www.nature.com/articles/nature17637"><u>Huth et al., 2016.</u></a>
          </p>
        </div>
    </div>


    <div class="container">
      <h4>My Contribution: Experiment Design, Preprocessing, Database Construction, Data Collection & Analysis</h4>

        <div class="col-sm-12 wow fadeInLeftBig">  
          <p class="lead">
             1. Constructed word stimulus set by filtering out true words from the English Lexicon Project and selecting non-words from Wuggy database (<a href="https://ray306.github.io/brain_NLP/stimuli.html#header-1"><u>word stimuli dataset</u></a>, English version)<br>
             2. Revised Python codes to present new experimental paradigms<br>
             3. Redesigned Python codes to include event codes (triggers)<br>
             4. Wrote Python codes to analyze cosine similarity between two words using GloVe models from NLP <br>
             5. Conducted EEG experiments independently: recruited participants (n=18), prepared participants' scalps, added EEG cream, used Brain Pycorder to monitor data collection<br>
             6. Used easyeeg package to preprocess raw datasets: artifact rejection and correction; averaging; filtering<br>
             7. Analyzed preprocessed data to detect the amplitude and latency of ERP waves, GFP, and topography<br>
          </p>
        </div>
      </div>

        <div class="container">
        <div class="col-sm-6 wow fadeInLeftBig">
          <img src="figures/fig2-2.png" alt="fig2-2" width="100%" height="50%">
            <p>Fig 2.2 Semantic representations in the human brain and word embedding models</p>
        </div>

        <div class="container">
          <div class="col-sm-6 wow fadeInRightBig">
            <img src="figures/fig2-3.png" alt="fig2-3" width="100%" height="50%">
              <p>Fig 2.3 Experimental procedure and single-trial correlation analysis</p>
          </div>

    </div>


    <div class="container">
      <h4>My Relevant Skills</h4>

      <div class="col-sm-7 wow fadeInLeftBig">  
        <p class="lead">
          1. neurolinguistics<br>
          2. natural language processing, python programming <br>
          3. ERP experiments design, EEG preprocessing, EEG data analysis<br>
        </p>
      </div>

      <div class="container">
        <div class="col-sm-5 wow fadeInRightBig">
          <img src="figures/fig2-4.png" alt="fig2-4" width="100%" height="50%">
            <p>Fig 2.4 Python programming</p>
        </div>

    </div>


    <div class="container">
      <h4>Results</h4>  

      <div class="col-sm-4 wow fadeInLeftBig">
        <img src="figures/fig2-5.png" alt="fig2-5" width="100%" height="50%">
      </div>

      <div class="col-sm-8 wow fadeInRightBig">        
        <p class="lead">
          â€¢ The validity of the EEG data was examined by checking ERP components using data averaged across all trials. ERP waveforms were plotted in several channels. One representative waveform shown here was from channel Cz. <br>
          â€¢ Early visual responses N1 and P2 as well as semantics-related N400 effects were shown in responses to both target and prime, consistent with well-established literature (Kutas and Federmeier 2011).<br>
        </p>
      </div>
    </div>


    <div class="container">
      <div class="col-sm-4 wow fadeInLeftBig">
        <img src="figures/fig2-6.png" alt="fig2-6" width="100%" height="50%">
      </div>

      <div class="col-sm-8 wow fadeInRightBig">        
        <p class="lead">
          â€¢ The dynamics of Global Field Power(GFP) was also plotted as a geometric mean of electric potentials across all sensors (Lehmann and Skrandies 1980) to visualize the distributed energy fluctuation. <br>
          â€¢ Similar evolution of ERP components was observed in the dynamics of GFP which included activity of all sensors, demonstrating the reliability of elicited data without the potential pitfalls of subjective bias.<br>
        </p>
      </div>
    </div>


    <div class="container">
      <div class="col-sm-4 wow fadeInLeftBig">
        <img src="figures/fig2-7.png" alt="fig2-7" width="100%" height="50%">
      </div>

      <div class="col-sm-8 wow fadeInRightBig">        
        <p class="lead">
          â€¢ The topographies across time for ERP responses to prime and target as well as the differences between the two (i.e., target minus prime) were also plotted to visualize the dynamics of activation patterns. 
          Consistent evolution of response patterns were demonstrated in topographic responses to prime and target, which suggests that common cognitive functions unfolded over time during the reading of these words at prime and target positions. 
          Topographic differences between target and prime showed magnitude differences in sensors over frontal and temporo-parietal regions around 275 ms
        </p>
      </div>
    </div>
      
    <div class="container">

      <div class="col-sm-4 wow fadeInLeftBig">
        <img src="figures/fig2-8.png" alt="fig2-8" width="100%" height="50%">
      </div>
      
      <div class="col-sm-8 wow fadeInRightBig">        
        <p class="lead">
          â€¢ From the correlation between EEG responses in each of the 32 channels at each of the 800 milliseconds and cosine similarities computed from computational models GloVe, we obtained a 32 Ã— 800-dimensional matrix of r values for GloVe.<br>
          â€¢ To estimate the overall predictability of each model, we averaged the absolute r values across channels, yielding a line of temporal progression of r for each word embedding model. <br>
          â€¢ We find that In <strong>Chinese</strong> version, GloVe-generated semantic similarity values significantly correlated with EEG response differences between 226 and 306 ms, while in <strong>English</strong> version, GloVe-generated semantic similarity values significantly correlated with EEG response differences between around <strong>420 and 440 ms</strong>.  <br>          
        </p>
      </div>

      <div class="col-sm-2 wow fadeInLeftBig">
      </div>

      <div class="col-sm-8 wow fadeInLeftBig">
        <img src="figures/fig2-9.png" alt="fig2-9" width="100%" height="50%">
      </div>


  </div>

     
  
 
     <!-- JavaScript -->
     <script src="js/jquery-1.10.2.js"></script>
     <script src="js/bootstrap.js"></script>
     <script src="js/owl.carousel.js"></script>
     <script src="js/script.js"></script>
     <!-- StikyMenu -->
     <script src="js/stickUp.min.js"></script>
     <script type="text/javascript">
       jQuery(function($) {
         $(document).ready( function() {
           $('.navbar-default').stickUp();
           
         });
       });
     
     </script>
     <!-- Smoothscroll -->
     <script type="text/javascript" src="js/jquery.corner.js"></script> 
     <script src="js/wow.min.js"></script>
     <script>
      new WOW().init();
     </script>
     <script src="js/classie.js"></script>
     <script src="js/uiMorphingButton_inflow.js"></script>
     <!-- Magnific Popup core JS file -->
     <script src="js/jquery.magnific-popup.js"></script> 
 </body>
 
 </html>
 